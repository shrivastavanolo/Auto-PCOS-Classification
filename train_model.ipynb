{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read excel sheet - class_labels for the training set\n",
    "df = pd.read_excel(r\"C:\\Users\\shrey\\OneDrive\\Documents\\misahub\\PCOSGen-train\\PCOSGen-train\\PCOSGen-train\\class_label.xlsx\",index_col='imagePath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Healthy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imagePath</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100image13.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100image2.jpg</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100image65.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100image71.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100image83.jpg</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Healthy\n",
       "imagePath              \n",
       "100image13.jpg        1\n",
       "100image2.jpg         1\n",
       "100image65.jpg        0\n",
       "100image71.jpg        0\n",
       "100image83.jpg        0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column to be predicted as y_test\n",
    "y_test=df['Healthy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.mobilenet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to preprocess image via path\n",
    "def preprocessingImage1(path):\n",
    "  image_data = ImageDataGenerator(zoom_range=0.2,shear_range=0.2,preprocessing_function= preprocess_input,horizontal_flip=True)\n",
    "  image = image_data.flow_from_directory(directory=path,target_size=(224,224),batch_size=32,class_mode='binary')\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path =r'C:\\Users\\shrey\\OneDrive\\Documents\\misahub\\PCOSGen-train\\PCOSGen-train\\PCOSGen-train\\images'\n",
    "train_data = preprocessingImage1(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten,Dense\n",
    "from keras.models import Model\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\shrey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Using base model MobileNet from keras\n",
    "base_model = MobileNet(input_shape=(224,224,3),include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= Flatten()(base_model.output)\n",
    "x= Dense(units=1,activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(base_model.input,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model for chosen optimizer, loss, metrics\n",
    "model.compile(optimizer=\"adam\",loss=keras.losses.binary_crossentropy,metrics=[keras.metrics.Recall(),\"acc\",keras.metrics.Precision(),keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "#add a checkpoint for the model \n",
    "mc = ModelCheckpoint(filepath=\"bestmodel.h5\",monitor='acc',verbose=1,save_best_only=True)\n",
    "\n",
    "#Early check points\n",
    "es = EarlyStopping(monitor=\"acc\",min_delta=0.01,patience=5,verbose=1)\n",
    "\n",
    "cb = [mc,es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.5586 - recall_16: 0.6641 - acc: 0.8146 - precision_3: 0.6591 - auc_2: 0.8049\n",
      "Epoch 1: acc improved from -inf to 0.81458, saving model to bestmodel.h5\n",
      "15/15 [==============================] - 8s 399ms/step - loss: 1.5586 - recall_16: 0.6641 - acc: 0.8146 - precision_3: 0.6591 - auc_2: 0.8049\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shrey\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 1.3736 - recall_16: 0.6351 - acc: 0.7792 - precision_3: 0.6438 - auc_2: 0.8098\n",
      "Epoch 2: acc did not improve from 0.81458\n",
      "15/15 [==============================] - 6s 411ms/step - loss: 1.3736 - recall_16: 0.6351 - acc: 0.7792 - precision_3: 0.6438 - auc_2: 0.8098\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.2522 - recall_16: 0.6160 - acc: 0.7958 - precision_3: 0.6063 - auc_2: 0.7879\n",
      "Epoch 3: acc did not improve from 0.81458\n",
      "15/15 [==============================] - 6s 405ms/step - loss: 1.2522 - recall_16: 0.6160 - acc: 0.7958 - precision_3: 0.6063 - auc_2: 0.7879\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - ETA: 0s - loss: 1.7690 - recall_16: 0.5532 - acc: 0.7542 - precision_3: 0.5865 - auc_2: 0.7497\n",
      "Epoch 4: acc did not improve from 0.81458\n",
      "15/15 [==============================] - 6s 405ms/step - loss: 1.7690 - recall_16: 0.5532 - acc: 0.7542 - precision_3: 0.5865 - auc_2: 0.7497\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - ETA: 0s - loss: 2.0116 - recall_16: 0.5448 - acc: 0.7688 - precision_3: 0.5935 - auc_2: 0.7563\n",
      "Epoch 5: acc did not improve from 0.81458\n",
      "15/15 [==============================] - 6s 412ms/step - loss: 2.0116 - recall_16: 0.5448 - acc: 0.7688 - precision_3: 0.5935 - auc_2: 0.7563\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - ETA: 0s - loss: 2.0429 - recall_16: 0.6875 - acc: 0.7833 - precision_3: 0.6266 - auc_2: 0.7988\n",
      "Epoch 6: acc did not improve from 0.81458\n",
      "15/15 [==============================] - 6s 425ms/step - loss: 2.0429 - recall_16: 0.6875 - acc: 0.7833 - precision_3: 0.6266 - auc_2: 0.7988\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "#train the model using train_data\n",
    "hist = model.fit(train_data,\n",
    "                           steps_per_epoch=15,\n",
    "                           epochs=50,\n",
    "                           validation_steps=16,\n",
    "                          callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss: 1.5586 - recall_16: 0.6641 - acc: 0.8146 - precision_3: 0.6591 - auc_2: 0.8049"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "========================================================================================================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
